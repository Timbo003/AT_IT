#single
# Create a ColumnTransformer to apply one-hot encoding to categorical features
max_tree_depth = 5 # max_depth=10 drinne lassen ???? ist nur drin, damit man es einfacher anpassen kann

preprocessor = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', numeric_features),
        ('cat', OneHotEncoder(), categorical_features)
    ])

# Create a Decision Tree classifier within a pipeline
clf = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(max_depth=max_tree_depth,random_state=42)) 
])

# Train the classifier on the training set
clf.fit(X_train, y_train)

# Make predictions on the testing set
y_pred = clf.predict(X_test)

# Calculate and print the accuracy of the classifier
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)



# just for testing 

# Create arrays to store max_depth and corresponding accuracies
depths = []
accuracies = []

# Loop through max depths from 1 to 10
for max_tree_depth in range(1, 5):
    # Create a ColumnTransformer to apply one-hot encoding to categorical features | wichtig!!!
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', 'passthrough', numeric_features),
            ('cat', OneHotEncoder(), categorical_features)
        ])

    # Create a Decision Tree classifier within a pipeline
    clf = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', DecisionTreeClassifier(max_depth=max_tree_depth, random_state=42))
    ])

    # Train the classifier on the training set
    clf.fit(X_train, y_train)

    # Make predictions on the testing set
    y_pred = clf.predict(X_test)

    # Calculate the accuracy of the classifier
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Max Depth: {max_tree_depth}, Accuracy: {accuracy}")

    # Store depth and accuracy in arrays
    depths.append(max_tree_depth)
    accuracies.append(accuracy)

# Plotting the graph
plt.plot(depths, accuracies, marker='o')
plt.title('Max Depth vs. Accuracy')
plt.xlabel('Max Depth')
plt.ylabel('Accuracy')
plt.show()

-------------------------


# For loop code DT
# Get all combinations of columns
big_data = []
data = []

column_combinations = []
for r in range(1, len(features) + 1):
    column_combinations.extend(combinations(features, r))

# Iterate through each combination
for combination in column_combinations:
    # Create a new DataFrame for the current combination
    x_run_train = X_train[list(combination)].copy()
    x_run_test = X_test[list(combination)].copy()

    max_tree_depth = 2 # max_depth=10 drinne lassen ???? ist nur drin, damit man es einfacher anpassen kann

    # Create a Decision Tree classifier within a pipeline
    clf = Pipeline([
        ('classifier', DecisionTreeClassifier(max_depth=max_tree_depth,random_state=42)) 
    ])

    # Train the classifier on the training set
    clf.fit(x_run_train, y_train)

    # Make predictions on the testing set
    y_pred = clf.predict(x_run_test)

    # Calculate and print the accuracy of the classifier
    accuracy = accuracy_score(y_test, y_pred)
    # Calculate and print precision, recall, and f1-score
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    average = (accuracy + precision + recall + f1) / 4

    print("Combination:", combination)
    print("Accuracy:", accuracy)
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1-Score:", f1)
    print("Average:", average)
    
    print("\n")

    #add combination, accuracy, precision, recall, f1 as an array inot the data array
    big_data = [].append([combination, accuracy, precision, recall, f1, average])

--------------


# For loop code DT
# Get all combinations of columns
big_data = []
data = []

column_combinations = []
for r in range(1, len(features) + 1):
    column_combinations.extend(combinations(features, r))

# Iterate through each combination
for combination in column_combinations:
    # Create a new DataFrame for the current combination
    x_run_train = X_train[list(combination)].copy()
    x_run_test = X_test[list(combination)].copy()

    max_tree_depth = 2 # max_depth=10 drinne lassen ???? ist nur drin, damit man es einfacher anpassen kann

    # Create a Decision Tree classifier within a pipeline
    clf = Pipeline([
        ('classifier', DecisionTreeClassifier(max_depth=max_tree_depth,random_state=42)) 
    ])

    # Train the classifier on the training set
    clf.fit(x_run_train, y_train)

    # Make predictions on the testing set
    y_pred = clf.predict(x_run_test)

    # Calculate and print the accuracy of the classifier
    accuracy = accuracy_score(y_test, y_pred)
    # Calculate and print precision, recall, and f1-score
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    average = (accuracy + precision + recall + f1) / 4

    print("Combination:", combination)
    print("Accuracy:", accuracy)
    print("Precision:", precision)
    print("Recall:", recall)
    print("F1-Score:", f1)
    print("Average:", average)
    
    print("\n")

    #add combination, accuracy, precision, recall, f1 as an array inot the data array
    big_data.append([combination, accuracy, precision, recall, f1, average])

# add the value with the highest average to data
print(big_data)

max_average = 0
for i in range(0, len(big_data)):
    if big_data[i][5] > max_average:
        max_average = big_data[i][5]
        data = big_data[i]


print("\n Data:")
print(data)

